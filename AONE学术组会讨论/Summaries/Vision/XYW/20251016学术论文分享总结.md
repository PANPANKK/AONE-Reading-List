**1. 论文基本信息**



论文标题： An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale

会议/期刊： ICLR 2021



**2. 研究背景与问题**



领域背景： 计算机视觉，图像分类。

核心问题： 在视觉领域，CNN一直是主导架构。Transformer在NLP领域取得巨大成功，但其在计算机视觉上的应用主要局限于与CNN结合。论文探索完全摒弃CNN，仅使用纯Transformer结构进行图像分类的可行性。

研究动机： Transformer的自注意力机制具有强大的全局建模能力，可能比CNN的局部卷积更有优势。



**3. 核心方法与创新点**



方法概述： 提出Vision Transformer模型。

关键技术： 将输入图像分割成固定大小的图像块，线性映射为序列，然后加上位置编码，直接输入到标准Transformer Encoder中。最后用一个额外的分类Token的输出进行图像分类

开创性架构： 首次证明了纯Transformer架构无需CNN，在图像分类任务上也能达到甚至超越SOTA水平。



**4.实验分析**

Vision Transformer 不仅能够在图像分类任务上达到或超越最先进的卷积神经网络（CNN）的性能，更重要的是，它能够在显著减少计算资源的前提下做到这一点。





**优点：**

架构简洁优雅，打破了CV领域对CNN的依赖。

**局限与不足：**

在没有大规模预训练的情况下，性能不如ResNet。

对计算资源要求较高。



**总结：**

改变学习态度，提高学习效率，汇报有价值的内容

